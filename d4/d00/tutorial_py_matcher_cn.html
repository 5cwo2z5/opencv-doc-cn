<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>OpenCV: 特征匹配</title>
<link href="../../opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
//<![CDATA[
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
//]]>
</script><script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">3.3.0</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<script type="text/javascript">
//<![CDATA[
function getLabelName(innerHTML) {
    var str = innerHTML.toLowerCase();
    // Replace all '+' with 'p'
    str = str.split('+').join('p');
    // Replace all ' ' with '_'
    str = str.split(' ').join('_');
    // Replace all '#' with 'sharp'
    str = str.split('#').join('sharp');
    // Replace other special characters with 'ascii' + code
    for (var i = 0; i < str.length; i++) {
        var charCode = str.charCodeAt(i);
        if (!(charCode == 95 || (charCode > 96 && charCode < 123) || (charCode > 47 && charCode < 58)))
            str = str.substr(0, i) + 'ascii' + charCode + str.substr(i + 1);
    }
    return str;
}
function addToggle() {
    var $getDiv = $('div.newInnerHTML').last();
    var buttonName = $getDiv.html();
    var label = getLabelName(buttonName.trim());
    $getDiv.attr("title", label);
    $getDiv.hide();
    $getDiv = $getDiv.next();
    $getDiv.attr("class", "toggleable_div label_" + label);
    $getDiv.hide();
}
//]]>
</script>
<!-- end header part -->
<!-- 制作者 Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "../../search",false,'搜索');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',true,false,'search.php','搜索');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../index.html">OpenCV 官方文档中文翻译（基于V3.3.0）</a></li><li class="navelem"><a class="el" href="../../d2/d3e/tutorial_py_table_of_contents_feature2d_cn.html">特征检测和描述符</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">特征匹配 </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>目标</h2>
<p>在这一章中，</p>
<ul>
<li>我们将看到如何将一个图片上的特征和其他图片上的特征匹配起来。</li>
<li>我们将使用OpenCV中的蛮力匹配器和FLANN匹配器。</li>
</ul>
<h2>蛮力匹配器基础</h2>
<p>蛮力匹配器很简单。 它采用第一组中的一个特征的描述符并且使用一些距离计算与第二组中的所有其他特征匹配。 返回最接近的一个。 对于BF匹配器，首先我们必须使用<code>cv2.BFMatcher()</code>来创建<code>BFMatcher</code>对象。 它需要两个可选的参数。 首先是<code>normType</code>。 它指定要使用的距离测量方法。 默认情况下，它是<code>cv2.NORM_L2</code>。 对于SIFT，SURF等（<code>cv2.NORM_L1</code>也在这些之中）。 对于像ORB，BRIEF，BRISK等基于二进制字符串的描述符，应该使用<code>cv2.NORM_HAMMING</code>，它使用汉明距离作为度量。 如果ORB使用<code>WTA_K == 3</code>或4，则应使用<code>cv2.NORM_HAMMING2</code>。</p>
<p>第二个参数是布尔变量<code>crossCheck</code>，其默认为false。 如果它为true，Matcher只返回值为$(i,j)$的那些匹配，使得集合A中的第i个描述符在集合B中具有第j个描述符作为最佳匹配，反之亦然。 也就是说，两组中的两个特征应该相互匹配。 它提供了一致的结果，这是D.Lowe在SIFT论文中提出的比率测试的一个很好的替代品。</p>
<p>一旦一个<code>BFMatcher</code>对象被创建，两个重要的方法是<code>BFMatcher.match()</code>和<code>BFMatcher.knnMatch()</code>。 第一个返回最佳匹配。 第二个返回k个最佳匹配，其中k由用户指定。当我们需要做额外的工作时，这可能是有用的。</p>
<p>就像我们使用<code>cv2.drawKeypoints()</code>来绘制关键点那样，<code>cv2.drawMatches()</code>帮助我们绘制匹配。 它将两个图像水平堆叠，并从第一个图像绘制到第二个图像，显示最佳匹配。 也有<code>cv2.drawMatchesKnn()</code>函数来绘制所有k个最好的匹配。 如果$k=2$，则会为每个关键点绘制两条匹配线。 所以如果我们要选择性地绘制它，我们必须传入一个mask。</p>
<p>让我们来看看SURF和ORB（使用不同的距离测量）的示例。</p>
<h3>用ORB描述符进行蛮力匹配</h3>
<p>在这里，我们将看到一个关于如何匹配两个图像之间的特征的简单例子。 在这种情况下，我有一个queryImage和trainImage。 我们将尝试使用特征匹配来在queryImage中查找trainImage。 （图片是/samples/c/box.png和/samples/c/box_in_scene.png）</p>
<p>我们使用ORB描述符来匹配特征。</p>
<p>让我们开始加载图像，找到描述符等。</p>
<div class="fragment"><div class="line">import numpy as np</div><div class="line">import cv2</div><div class="line">import matplotlib.pyplot as plt</div><div class="line">img1 = cv2.imread(&#39;box.png&#39;,0)          # queryImage</div><div class="line">img2 = cv2.imread(&#39;box_in_scene.png&#39;,0) # trainImage</div><div class="line"># 初始化ORB检测器</div><div class="line">orb = cv2.ORB_create()</div><div class="line"># 用ORB寻找关键点和描述符</div><div class="line">kp1, des1 = orb.detectAndCompute(img1,None)</div><div class="line">kp2, des2 = orb.detectAndCompute(img2,None)</div></div><!-- fragment --><p>接下来我们创建一个距离测量方法为<code>cv2.NORM_HAMMING</code>的BFMatcher对象（因为我们使用的是ORB），为了获得更好的结果，我们将打开<code>crossCheck</code>。 然后我们使用<code>Matcher.match()</code>方法获得两幅图像中的最佳匹配。 我们按照距离升序对它们进行排序，以便最佳匹配（低距离）出现在前面。 然后我们只画出前10个匹配（只是为了可见性考虑。你可以随意增加这个值）。</p>
<div class="fragment"><div class="line"># 创建BFMatcher对象</div><div class="line">bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)</div><div class="line"># 匹配描述符</div><div class="line">matches = bf.match(des1,des2)</div><div class="line"># 按照距离排序</div><div class="line">matches = sorted(matches, key = lambda x:x.distance)</div><div class="line"># 画出前10个匹配</div><div class="line">img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:10], flags=2)</div><div class="line">plt.imshow(img3)</div><div class="line">plt.show()</div></div><!-- fragment --><p>下面是我得到的结果：</p>
<div class="image">
<img src="../../matcher_result1.jpg" alt="matcher_result1.jpg"/>
<div class="caption">
image</div></div>
 <h2>Matcher对象是什么？</h2>
<p><code>matches = bf.match(des1,des2)</code>这行的结果是DMatch对象的列表。 DMatch对象具有以下属性：</p>
<ul>
<li><code>DMatch.distance</code> - 描述符之间的距离。 越低表示匹配地越好。</li>
<li><code>DMatch.trainIdx</code> - 训练集中描述符的索引。</li>
<li><code>DMatch.queryIdx</code> - 查询集中描述符的索引。</li>
<li><code>DMatch.imgIdx</code> - 训练图片的索引。</li>
</ul>
<h2>用SIFT描述符进行蛮力匹配和比率测试</h2>
<p>这一次，我们将使用<code>BFMatcher.knnMatch()</code>来获得k个最佳匹配。 在这个例子中，我们将采取k = 2，以便我们可以应用在D.Lowe的论文中提到的比率测试。</p>
<div class="fragment"><div class="line">import numpy as np</div><div class="line">import cv2</div><div class="line">from matplotlib import pyplot as plt</div><div class="line">img1 = cv2.imread(&#39;box.png&#39;,0)          # queryImage</div><div class="line">img2 = cv2.imread(&#39;box_in_scene.png&#39;,0) # trainImage</div><div class="line"># 初始化SIFT检测器</div><div class="line">sift = cv2.SIFT()</div><div class="line"># 用SIFT搜索关键点和描述子</div><div class="line">kp1, des1 = sift.detectAndCompute(img1,None)</div><div class="line">kp2, des2 = sift.detectAndCompute(img2,None)</div><div class="line"># 用默认的BFMatcher进行匹配</div><div class="line">bf = cv2.BFMatcher()</div><div class="line">matches = bf.knnMatch(des1,des2, k=2)</div><div class="line"># 进行比率测试</div><div class="line">good = []</div><div class="line">for m,n in matches:</div><div class="line">    if m.distance &lt; 0.75*n.distance:</div><div class="line">        good.append([m])</div><div class="line"># 用cv2.drawMatchesKnn绘制一个列表的匹配对象</div><div class="line">img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,flags=2)</div><div class="line">plt.imshow(img3)</div><div class="line">plt.show()</div></div><!-- fragment --><p>下面是结果：</p>
<div class="image">
<img src="../../matcher_result2.jpg" alt="matcher_result2.jpg"/>
<div class="caption">
image</div></div>
 <h2>基于FLANN的Matcher</h2>
<p>FLANN，即快速近似最邻近库。 它包含一组经过优化的算法，用于大数据集以及高维特征数据集中的快速最近邻搜索。 对于大数据集，它的工作速度比BFMatcher快。 我们将看到基于FLANN的匹配器的第二个例子。</p>
<p>对于基于FLANN的匹配器，我们需要传递两个字典，指定要使用的算法，相关的参数等。首先是<code>IndexParams</code>。 对于各种算法，要传递的信息在FLANN文档中进行了解释。 总而言之，对于像SIFT，SURF等算法，您可以传入以下这些东西：</p>
<div class="fragment"><div class="line">FLANN_INDEX_KDTREE = 1</div><div class="line">index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)</div></div><!-- fragment --><p>在使用ORB的时候，你可以传入下面这些值。 这些值都是文档推荐的值，但在某些情况下这些值不会提供所需的结果。 而其他值却工作正常。</p>
<div class="fragment"><div class="line">FLANN_INDEX_LSH = 6</div><div class="line">index_params= dict(algorithm = FLANN_INDEX_LSH,</div><div class="line">                    table_number = 6, # 12</div><div class="line">                    key_size = 12,     # 20</div><div class="line">                    multi_probe_level = 1) #2</div></div><!-- fragment --><p>第二个字典是<code>SearchParams</code>。 它指定了索引中的树应递归遍历的次数。 更高的值会提高精度，但也需要更多的时间。 如果你想改变这个值，传入<code>search_params = dict(checks = 100)</code>。</p>
<p>有了这些信息，我们就准备好了。</p>
<div class="fragment"><div class="line">import numpy as np</div><div class="line">import cv2</div><div class="line">from matplotlib import pyplot as plt</div><div class="line">img1 = cv2.imread(&#39;box.png&#39;,0)          # queryImage</div><div class="line">img2 = cv2.imread(&#39;box_in_scene.png&#39;,0) # trainImage</div><div class="line"># 初始化SIFT检测器</div><div class="line">sift = cv2.SIFT()</div><div class="line"># 用SIFT找到关键点和描述符</div><div class="line">kp1, des1 = sift.detectAndCompute(img1,None)</div><div class="line">kp2, des2 = sift.detectAndCompute(img2,None)</div><div class="line"># FLANN参数</div><div class="line">FLANN_INDEX_KDTREE = 1</div><div class="line">index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)</div><div class="line">search_params = dict(checks=50)   # 或者传入空的字典</div><div class="line">flann = cv2.FlannBasedMatcher(index_params,search_params)</div><div class="line">matches = flann.knnMatch(des1,des2,k=2)</div><div class="line"># 只需要画出好的匹配，所以创建一个mask</div><div class="line">matchesMask = [[0,0] for i in xrange(len(matches))]</div><div class="line"># 比率测试</div><div class="line">for i,(m,n) in enumerate(matches):</div><div class="line">    if m.distance &lt; 0.7*n.distance:</div><div class="line">        matchesMask[i]=[1,0]</div><div class="line">        draw_params = dict(matchColor = (0,255,0),</div><div class="line">                        singlePointColor = (255,0,0),</div><div class="line">                        matchesMask = matchesMask,</div><div class="line">                        flags = 0)</div><div class="line">        img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)</div><div class="line">plt.imshow(img3,)</div><div class="line">plt.show()</div></div><!-- fragment --><p>可以看见下面的结果。</p>
<div class="image">
<img src="../../matcher_flann.jpg" alt="matcher_flann.jpg"/>
<div class="caption">
image</div></div>
 </div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
生成于 2018年 七月 1日 星期日 11:40:43 , 为 OpenCV使用  &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
<script type="text/javascript">
//<![CDATA[
function addButton(label, buttonName) {
    var b = document.createElement("BUTTON");
    b.innerHTML = buttonName;
    b.setAttribute('class', 'toggleable_button label_' + label);
    b.onclick = function() {
        $('.toggleable_button').css({
            border: '2px outset',
            'border-radius': '4px'
        });
        $('.toggleable_button.label_' + label).css({
            border: '2px inset',
            'border-radius': '4px'
        });
        $('.toggleable_div').css('display', 'none');
        $('.toggleable_div.label_' + label).css('display', 'block');
    };
    b.style.border = '2px outset';
    b.style.borderRadius = '4px';
    b.style.margin = '2px';
    return b;
}
function buttonsToAdd($elements, $heading, $type) {
    if ($elements.length === 0) {
        $elements = $("" + $type + ":contains(" + $heading.html() + ")").parent().prev("div.newInnerHTML");
    }
    var arr = jQuery.makeArray($elements);
    var seen = {};
    arr.forEach(function(e) {
        var txt = e.innerHTML;
        if (!seen[txt]) {
            $button = addButton(e.title, txt);
            if (Object.keys(seen).length == 0) {
                var linebreak1 = document.createElement("br");
                var linebreak2 = document.createElement("br");
                ($heading).append(linebreak1);
                ($heading).append(linebreak2);
            }
            ($heading).append($button);
            seen[txt] = true;
        }
    });
    return;
}
$("h2").each(function() {
    $heading = $(this);
    $smallerHeadings = $(this).nextUntil("h2").filter("h3").add($(this).nextUntil("h2").find("h3"));
    if ($smallerHeadings.length) {
        $smallerHeadings.each(function() {
            var $elements = $(this).nextUntil("h2,h3").filter("div.newInnerHTML");
            buttonsToAdd($elements, $(this), "h3");
        });
    } else {
        var $elements = $(this).nextUntil("h2").filter("div.newInnerHTML");
        buttonsToAdd($elements, $heading, "h2");
    }
});
$(".toggleable_button").first().click();
var $clickDefault = $('.toggleable_button.label_python').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
$clickDefault = $('.toggleable_button.label_cpp').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
//]]>
</script>
</body>
</html>
