<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<title>OpenCV: 光流</title>
<link href="../../opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
//<![CDATA[
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
//]]>
</script><script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">3.3.0</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<script type="text/javascript">
//<![CDATA[
function getLabelName(innerHTML) {
    var str = innerHTML.toLowerCase();
    // Replace all '+' with 'p'
    str = str.split('+').join('p');
    // Replace all ' ' with '_'
    str = str.split(' ').join('_');
    // Replace all '#' with 'sharp'
    str = str.split('#').join('sharp');
    // Replace other special characters with 'ascii' + code
    for (var i = 0; i < str.length; i++) {
        var charCode = str.charCodeAt(i);
        if (!(charCode == 95 || (charCode > 96 && charCode < 123) || (charCode > 47 && charCode < 58)))
            str = str.substr(0, i) + 'ascii' + charCode + str.substr(i + 1);
    }
    return str;
}
function addToggle() {
    var $getDiv = $('div.newInnerHTML').last();
    var buttonName = $getDiv.html();
    var label = getLabelName(buttonName.trim());
    $getDiv.attr("title", label);
    $getDiv.hide();
    $getDiv = $getDiv.next();
    $getDiv.attr("class", "toggleable_div label_" + label);
    $getDiv.hide();
}
//]]>
</script>
<!-- end header part -->
<!-- 制作者 Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "../../search",false,'搜索');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('../../',true,false,'search.php','搜索');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../index.html">OpenCV 官方文档中文翻译（基于V3.3.0）</a></li><li class="navelem"><a class="el" href="../../d3/d2c/tutorial_py_table_of_contents_video_cn.html">视频分析</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">光流 </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>目标</h2>
<p>在这一章当中，</p>
<ul>
<li>我们将理解光流的概念及使用Lucas-Kanade方法估计光流。</li>
<li>我们将使用像<code>cv2.calcOpticalFlowPyrLK()</code>这样的函数来跟踪视频中的特征点。</li>
</ul>
<h2>光流</h2>
<p>光流是由物体或相机的运动引起的图像对象在两个连续帧之间的视在运动模式。它是2D矢量场，其中每个矢量是一个位移矢量，表示点从第一帧到第二帧的移动。考虑下面的图片（图片提供：<a href="https://zh.wikipedia.org/wiki/光流法">维基百科关于光流的文章</a>）。</p>
<div class="image">
<img src="../../optical_flow_basic1.jpg" alt="optical_flow_basic1.jpg"/>
<div class="caption">
image</div></div>
<p> 它显示了一个连续5帧移动的球。箭头显示其位移矢量。光流在许多领域中有应用，像：</p>
<ul>
<li>动作结构</li>
<li>视频压缩</li>
<li>视频稳定</li>
<li>……</li>
</ul>
<p>光流在几个假设下工作：</p>
<ul>
<li>对象的像素强度在连续的帧之间不会改变。</li>
<li>相邻像素具有相似的运动。</li>
</ul>
<p>考虑第一帧中的一个像素$I(x,y,t)$（一个新的维度，时间，在这里被添加进来，之前我们只处理静态图像，所以不需要时间）。它在$dt$时间之后的下一帧中移动距离$(dx,dy)$ 。因此，由于这些像素是相同的，而且强度不变，所以我们可以说： $$ I(x,y,t) = I(x+dx, y+dy, t+dt) $$ 对右边进行泰勒展开，移除常数项并除以$dt$，会得到： $$ f_x u + f_y v + f_t = 0\ where\ f_x = { f}{ x} \ 2f_y = { f}{ y}\ 3u = {dx}{dt} \ 4v = {dy}{dt} $$ 以上等式称为光流方程。在这里，我们可以找到$f_x$和$f_y$，它们是图像梯度。同样，$f_t$是沿着时间方向上的的梯度。但$(u,v)$是未知的。我们不能在有两个未知的变量的条件下解这个方程。有几种方法可以解决这个问题，其中之一就是Lucas-Kanade方法。</p>
<h2>Lucas-Kanade方法</h2>
<p>之前我们已经假设了所有的相邻像素都会有相似的运动。Lucas-Kanade方法需要一个3x3的块。9点都有相同的动作。我们可以找到这9个点的$(f_x, f_y, f_t)$。所以现在我们的问题就是求解9个有两个未知变量的方程。一个更好的方法是用最小二乘法拟合。下面是两个方程-两个未知量的最终解决方案，解这个方程来得到最终的解。 $$ {bmatrix} u \ v {bmatrix} = {bmatrix} {i}{f_{x_i}}^2 &amp; {i}{f_{x_i} f_{y_i} } \ {i}{f_{x_i} f_{y_i}} &amp; {i}{f_{y_i}}^2 {bmatrix}^{-1} {bmatrix}</p><ul>
<li>{i}{f_{x_i} f_{t_i}} \</li>
<li>{i}{f_{y_i} f_{t_i}} {bmatrix} $$ （看看这里的逆矩阵与Harris角点检测器的相似性。这也证明了角点是更好的跟踪用的点。）</li>
</ul>
<p>所以从用户的角度来看，思路很简单，我们给出一些跟踪点，我们得到这些点的光流向量。但是也有一些问题。到现在为止，我们都在处理小规模的运动。当运动很大时这就会失败。所以我们再使用图像金字塔。当我们向金字塔上方走时，小的运动会被移除，大的运动会变成小的运动。因此，在那里应用Lucas-Kanade法，我们可以得到缩放过的光流。</p>
<h2>OpenCV中的Lucas-Kanade光流</h2>
<p>OpenCV在一个函数<code>cv2.calcOpticalFlowPyrLK()</code>中提供了所有这些。在这里，我们创建一个简单的应用程序，跟踪视频中的一些点。为了决定要跟踪的点，我们使用<code>cv2.goodFeaturesToTrack()</code>。我们取第一帧，检测一些Shi-Tomasi角点，然后用Lucas-Kanade光流迭代地跟踪这些点。对于函数<code>cv2.calcOpticalFlowPyrLK()</code>，我们传递前一帧，前面的点和下一帧。如果找到下一个点，则返回下一个点以及一些状态值为1的值，否则为零。我们迭代地将这些下一个点作为下一个步骤的前几个点。请参阅下面的代码：</p>
<div class="fragment"><div class="line">import numpy as np</div><div class="line">import cv2</div><div class="line"></div><div class="line">cap = cv2.VideoCapture(&#39;slow.flv&#39;)</div><div class="line"></div><div class="line"># ShiTomasi角点检测参数</div><div class="line">feature_params = dict( maxCorners = 100,</div><div class="line">                       qualityLevel = 0.3,</div><div class="line">                       minDistance = 7,</div><div class="line">                       blockSize = 7 )</div><div class="line"></div><div class="line"># lucas kanade光流参数</div><div class="line">lk_params = dict( winSize  = (15,15),</div><div class="line">                  maxLevel = 2,</div><div class="line">                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))</div><div class="line"></div><div class="line"># 一些随机颜色</div><div class="line">color = np.random.randint(0,255,(100,3))</div><div class="line"></div><div class="line"># 取第一帧，寻找角点</div><div class="line">ret, old_frame = cap.read()</div><div class="line">old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)</div><div class="line">p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)</div><div class="line"></div><div class="line"># 创建一个mask，为了绘图方便</div><div class="line">mask = np.zeros_like(old_frame)</div><div class="line"></div><div class="line">while(1):</div><div class="line">    ret,frame = cap.read()</div><div class="line">    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</div><div class="line"></div><div class="line">    # 计算光流</div><div class="line">    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)</div><div class="line"></div><div class="line">    # 选择较好的点</div><div class="line">    good_new = p1[st==1]</div><div class="line">    good_old = p0[st==1]</div><div class="line"></div><div class="line">    # 画出轨迹</div><div class="line">    for i,(new,old) in enumerate(zip(good_new,good_old)):</div><div class="line">        a,b = new.ravel()</div><div class="line">        c,d = old.ravel()</div><div class="line">        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)</div><div class="line">        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)</div><div class="line">    img = cv2.add(frame,mask)</div><div class="line"></div><div class="line">    cv2.imshow(&#39;frame&#39;,img)</div><div class="line">    k = cv2.waitKey(30) &amp; 0xff</div><div class="line">    if k == 27:</div><div class="line">        break</div><div class="line"></div><div class="line">    # 更新前面的帧和点</div><div class="line">    old_gray = frame_gray.copy()</div><div class="line">    p0 = good_new.reshape(-1,1,2)</div><div class="line"></div><div class="line">cv2.destroyAllWindows()</div><div class="line">cap.release()</div></div><!-- fragment --><p>（这个代码并没有检查下一个关键点的正确性，所以即使任何特征点在图像中消失了，光流也有可能找到可能看起来接近它的下一个点。所以要做一个健壮的追踪程序的话，就要在特定的时间间隔内检测一次角点，OpenCV示例中每隔5帧就会采集一次样本，找出特征点，并对所得到的光流点进行反向检查，只选择好的样本点，见samples/python/lk_track.py）。</p>
<p>下面是我们的到的结果：</p>
<div class="image">
<img src="../../opticalflow_lk.jpg" alt="opticalflow_lk.jpg"/>
<div class="caption">
image</div></div>
 <h2>OpenCV中的密集光流</h2>
<p>Lucas-Kanade方法计算稀疏特征集的光流（在我们的例子中，使用Shi-Tomasi算法检测角点）。 OpenCV提供了另一种算法来查找密集光流。它计算帧中所有点的光流。它基于Gunner Farneback的算法，该算法在Gunner Farneback于2003年的《Two-Frame Motion Estimation Based on Polynomial Expansion》中有所解释。</p>
<p>以下示例显示如何使用上述算法找到密集的光流。我们得到一个带有光流矢量的双通道阵列，$(u,v)$。我们查找他们的幅度和方向。我们对结果进行颜色编码以实现更好的可视化。方向对应于图像的色调值。 幅度对应于价值平面。 请参阅下面的代码：</p>
<div class="fragment"><div class="line">import cv2</div><div class="line">import numpy as np</div><div class="line">cap = cv2.VideoCapture(&quot;vtest.avi&quot;)</div><div class="line"></div><div class="line">ret, frame1 = cap.read()</div><div class="line">prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)</div><div class="line">hsv = np.zeros_like(frame1)</div><div class="line">hsv[...,1] = 255</div><div class="line"></div><div class="line">while(1):</div><div class="line">    ret, frame2 = cap.read()</div><div class="line">    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)</div><div class="line"></div><div class="line">    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)</div><div class="line"></div><div class="line">    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])</div><div class="line">    hsv[...,0] = ang*180/np.pi/2</div><div class="line">    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)</div><div class="line">    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)</div><div class="line"></div><div class="line">    cv2.imshow(&#39;frame2&#39;,bgr)</div><div class="line">    k = cv2.waitKey(30) &amp; 0xff</div><div class="line">    if k == 27:</div><div class="line">        break</div><div class="line">    elif k == ord(&#39;s&#39;):</div><div class="line">        cv2.imwrite(&#39;opticalfb.png&#39;,frame2)</div><div class="line">        cv2.imwrite(&#39;opticalhsv.png&#39;,bgr)</div><div class="line">    prvs = next</div><div class="line"></div><div class="line">cap.release()</div><div class="line">cv2.destroyAllWindows()</div></div><!-- fragment --><p>下面是结果：</p>
<div class="image">
<img src="../../opticalfb.jpg" alt="opticalfb.jpg"/>
<div class="caption">
image</div></div>
<p> OpenCV在密集光流上有一个高级的示例，请参阅samples/python/opt_flow.py。</p>
<h2>练习</h2>
<ul>
<li>查看samples/python/lk_track.py中的代码。尝试理解代码。</li>
<li>查看samples/python/opt_flow.py中的代码。尝试理解代码。 </li>
</ul>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
生成于 2018年 七月 1日 星期日 11:40:44 , 为 OpenCV使用  &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
<script type="text/javascript">
//<![CDATA[
function addButton(label, buttonName) {
    var b = document.createElement("BUTTON");
    b.innerHTML = buttonName;
    b.setAttribute('class', 'toggleable_button label_' + label);
    b.onclick = function() {
        $('.toggleable_button').css({
            border: '2px outset',
            'border-radius': '4px'
        });
        $('.toggleable_button.label_' + label).css({
            border: '2px inset',
            'border-radius': '4px'
        });
        $('.toggleable_div').css('display', 'none');
        $('.toggleable_div.label_' + label).css('display', 'block');
    };
    b.style.border = '2px outset';
    b.style.borderRadius = '4px';
    b.style.margin = '2px';
    return b;
}
function buttonsToAdd($elements, $heading, $type) {
    if ($elements.length === 0) {
        $elements = $("" + $type + ":contains(" + $heading.html() + ")").parent().prev("div.newInnerHTML");
    }
    var arr = jQuery.makeArray($elements);
    var seen = {};
    arr.forEach(function(e) {
        var txt = e.innerHTML;
        if (!seen[txt]) {
            $button = addButton(e.title, txt);
            if (Object.keys(seen).length == 0) {
                var linebreak1 = document.createElement("br");
                var linebreak2 = document.createElement("br");
                ($heading).append(linebreak1);
                ($heading).append(linebreak2);
            }
            ($heading).append($button);
            seen[txt] = true;
        }
    });
    return;
}
$("h2").each(function() {
    $heading = $(this);
    $smallerHeadings = $(this).nextUntil("h2").filter("h3").add($(this).nextUntil("h2").find("h3"));
    if ($smallerHeadings.length) {
        $smallerHeadings.each(function() {
            var $elements = $(this).nextUntil("h2,h3").filter("div.newInnerHTML");
            buttonsToAdd($elements, $(this), "h3");
        });
    } else {
        var $elements = $(this).nextUntil("h2").filter("div.newInnerHTML");
        buttonsToAdd($elements, $heading, "h2");
    }
});
$(".toggleable_button").first().click();
var $clickDefault = $('.toggleable_button.label_python').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
$clickDefault = $('.toggleable_button.label_cpp').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
//]]>
</script>
</body>
</html>
